\chapter{Conclusions}
\label{c6}

In this thesis we presented a plethora of biomedical information extraction systems composed of machine learning models, knowledge-based methods, or rule-based approaches built with handcrafted heuristics.
These were applied and evaluated in textual data from biomedical literature and clinical reports.
Particularly, we investigated solutions for the \as{nlp} tasks of word sense disambiguation, entity linking, document classification, text similarity measurement, and relation extraction.
The application of these techniques contributes to improved information extraction from the unstructured text found in biomedical literature which is relevant for molecular biology, biomedicine, and chemistry \parencite{krallinger2005a,krallinger2017b}.
For example, finding biological entities such as gene and protein names, and their relationships, in the millions of articles that exist in the literature helps to unveil hidden information and provide hints for new discoveries.

In this last chapter, we highlight the key contributions of our thesis work, show limitations of our proposed methods, and point the reader to future research directions.


\section{Key contributions}

The main contributions of this thesis are supported by extensive and detailed experiments that we performed in the different levels, or tasks, of a complete pipelined information extraction system.
These contributions, in many biomedical text mining tasks, are summarized below:

\begin{itemize}

\item
We proposed a new method based on external knowledge captured from standard medical terminologies to improve biomedical word sense disambiguation in scientific articles.
Moreover, we compared this approach with supervised learning classifiers and verified that the use of ground-truth training instances allows to achieve higher accuracies, but knowledge-based systems have the ability to adapt (generalize) to different ambiguous concepts without the need of training samples.

\item
We developed a knowledge-based method for medical concept normalization where entity mentions in clinical text such as medications, disorders, and medical treatments are linked to unique codes from standard medical terminologies.
The system, based on pre-trained biomedical word embeddings, consists in a straightforward yet effective computation: the cosine similarity between (1)~the vector embedding of the target entity mention and (2)~every pre-calculated concept embedding from the training subset (of the corpus being used) and the \as{umls} database (considering only the RxNorm and \as{snomed}~CT vocabularies in the specific work that was conducted).

\item
We investigated the use of classical machine learning and convolutional recurrent neural networks for document triage.
Our deep learning models showed competitive performance in selecting \as{pubmed} abstracts that contain protein--protein interactions affected by genetic mutations.

\item
Regarding clinical text classification, we created a hybrid system for automatic patient cohort selection where clinical records were used to find if the patients met certain selection criteria for clinical trials.
We concluded that, due to the small size of the dataset and its high imbalance in labels, handcrafted rules performed overall better, while for some, more balanced criteria, machine learning models proved effective.

\item
We studied the use of word and sentence embeddings with neural network models to quantify the semantic textual similarity between clinical sentences.
Results with sentence embeddings achieved better performance in comparison to word embeddings, which made us conclude that sentence vectors generated by BioSentVec \parencite{chen2019g} provided a superior semantic representation.
Also, we observed that pre-processing the sentences with different levels of granularity, such as stop words removal or converting the numbers to their textual form, had a considerable impact with word embeddings but deteriorated performance when using sentence embeddings.
Therefore we established that sentence embeddings not only provide a preferable representation but also they require less effort in `fine-tuning' the input textual data.

\item
Regarding the task of relation extraction we investigated and evaluated the use of recurrent and convolutional neural networks for identifying interactions between chemicals and proteins in \as{pubmed} abstracts.
Our best method uses a small feature vector (narrow instance representation), from up to only 10 words per each candidate pair.
Our \as{bilstm} network showed improved performance and comparable results to other works.
Finally, we performed an extensive error analysis.

\end{itemize}

In short, in this thesis we proposed different methods for various information extraction tasks applied within the biomedical domain.
The majority of them were machine learning--based (some being deep neural networks), and the remaining consisted of knowledge-based systems or approaches with heuristics.
We conclude that machine learning methods are in general `easier to teach'---require less feature engineering, model handcrafting and fine-tuning---and can obtain better results but at the cost of sufficient and high-quality labeled data frequently annotated in advance by domain experts.

The existence of annotated datasets and lexical resources is in fact a primary requirement for information extraction.
Without access to the free text found in biomedical literature or eletronic health records this work would be impractical.
A related requisite is the existence of ground-truth or high-quality data, relevant for biomedical text mining, such as (1)~annotated datasets, and (2)~curated vocabularies, terminologies, and databases.
These resources are fundamental because they endow the researchers with the data needed for creating their information extraction systems.

Annotated datasets by domain experts, such as documents with biomedical entities and their interactions identified, are important for assessing and comparing the developed methods, and help to find out what approaches work best.
Since these corpora are associated with gold-standard labels (annotations) they are favored for supervised machine learning models that learn from training data.
However, a dataset may be considered small and not provide enough training samples for a machine learning model to achieve an acceptable performance; in these cases other approaches based on heuristics or external knowledge should be explored.

Fortunately, corpora for biomedical text mining is becoming less scarce due to the increasing interest for automatic solutions that can extract information from the text \parencite{rosarioferreira2021a}.
Creation of these datasets is often performed manually by domain expert curators, such as biologists, chemists, or pharmacologists, with the help of software tools for text annotation \parencite{neves2014a,neves2021a}---this is especially the case when entity mentions and relations need to be marked in a document.
On the other hand, some researchers already proposed (semi-)automatic procedures to alleviate the manual efforts of curation.
For instance, \textcite{jimenoyepes2011a} present an automatic method to create a dataset for biomedical \as{wsd}, though they took benefit from the manual \as{mesh} indexing that is routinely made by \as{nlm} experts.
In another work, \textcite{perezperez2022a} proposed a semi-automatic workflow for supporting a biomedical relation extraction curation task: they implement a deep learning model that learns from the decisions of the curators in iterative annotation rounds and show potential relevant relations in next rounds.

In this thesis, despite of our broad use of gold-standard datasets for biomedical information extraction we did not investigate the creation of these since it was not one of the goals of this work---furthermore it would require interdisciplinary cooperation and qualified manpower for expert curation.
Nevertheless we affirm that a straightforward approach for improving the performance of our methods would be the production and availability of more high-quality annotated data; since, in machine learning, a higher number of training samples usually leads to better performance and better generalization to unseen data.
However, this forms an unrealistic or difficult scenario because data itself is limited and further manual annotation is a long, arduous, and costly task.
Also, the use of larger datasets for training machine learning models (such as neural networks) would imply an increase in the training time and likely require more potent computer resources.


\section{Limitations}

As any developed solution for biomedical text mining our proposed methods have shortcomings or requirements that may restrict their suitability or reduce their performance in real-world applications.
In this section we present specific limitations or drawbacks of our methods:

\begin{itemize}

\item
Regarding the biomedical \as{wsd} task, the MSH WSD dataset contains \as{pubmed} abstracts in which the ambiguous terms appear.
However, we presume that in some cases access to the full-text article could prove relevant for finding the correct sense of an ambiguous term.
We did not explore this, yet both our approaches---supervised learning and knowledge-based---could be adapted to be applied to the full-text.

Similarly, our word embedding models were generated using only the text from \as{pubmed} abstracts; and we did not investigate if adding full-text articles from \as{pubmed} Central (\as{pmc}) would be beneficial.

Also, our knowledge-based method relies on textual definitions, extracted from \as{umls} knowledge sources, for every \as{cui} (Concept Unique Identifier) to create \textit{concepts embeddings}.
During our preliminary experiments we inspected some of these descriptions and found that some were short (containing only a few words), and therefore we hypothesize that the embedding representations, and the overall method, would improve with more complete and correct definitions.

\item
In the medical concept normalization task our proposed system only uses the mention text of the target entity to be normalized, which in some cases is not self-explanatory.
We hypothesize that the context around the entities would provide more information and improve the normalization accuracy.
\textcite{luo2019a}, the authors of the MCN corpus, also clarified that contextual information affects the results of normalization because annotators may interpret the context differently.
They further explained that they only required the annotators to use contextual information when the mention itself did not provide enough information.

In clinical text, our model directly uses the vector embeddings of abbreviated terms, considering their (lowercased) surface form.
This may not provide sufficient information, and a hybrid approach combining (1)~word embeddings and (2)~external dictionaries of abbreviations with their respective long forms could be helpful for disambiguation and normalization.

\item
We proposed the use of supervised learning methods for biomedical document triage.
The aim was to detect if \as{pubmed} abstracts were relevant, or not, for extracting protein--protein interactions affected by genetic mutations.
We experimented with adding more training data employing the BioCreative~III~\as{ppi} corpus \parencite{krallinger2011a} in a self-training approach, but the results only improved by a tiny margin (0.12\%~F1-score in the official test set).
We believe that including external corpora for training can be more beneficial but further investigation is required.

\item
In the task of patient cohort selection for clinical trials, we found that rule-based methods were more adequate given the relatively small size of the dataset.
However, the results show that our heuristics were severely overfit to the training set and could be improved with unbiased and specialized knowledge from physicians or clinical experts.

Additionally, we tested removing tabular information from the clinical documents to restrict their content to free text, but we did not find significant differences in the results.
Extracting the tabular information and customizing its analysis, instead of discarding it, could be a more viable approach for some criteria because tables may contain clinical tests' measurements, or dosages of medications, relevant for inferring the patient health status.

\item
When measuring the semantic textual similarity between clinical sentences, we observed that our model could more easily identify pairs of highly similar or dissimilar sentences, but struggled with sentences that were not equivalent but shared identical portions or were about the same subject.

\item
For our chemical--protein relation extraction system, we pre-processed the \mbox{\as{biogrid}} database \parencite{chatraryamontri2017a} for extracting additional chemical--protein interactions for training the model but the results deteriorated and we believe that a more rigorous treatment of the data would be necessary.

Also, we note that our model is limited to extracting relations within sentences and requires that chemical and protein entities are previously identified, since performing named entity recognition was out of scope in this task.

\end{itemize}


\section{Future research}

As highlighted in the previous section, our proposed methods have some limitations and unexplored details that can be further studied or addressed in upcoming research.
We now point out other aspects that can be investigated for improving biomedical text mining according to state-of-the-art research.

The use of word embeddings was investigated in every biomedical \as{nlp} task presented in this thesis.
In our initial experiments, we pre-trained our word embedding models employing the word2vec algorithm from the Gensim library \parencite{rehurek2010a}, using the continuous bag-of-words and skip-gram architectures proposed by \textcite{mikolov2013b}.
Then, we tested the BioWordVec model \parencite{chen2019g} that consists of word vectors trained on biomedical and clinical text and is based on the fastText algorithm that takes into account subword information \parencite{bojanowski2017a}.
From our experiments we concluded that BioWordVec provided superior representations, also having the advantage of computing out-of-vocabulary words since fastText exploits subword information.

Word embeddings pre-trained using the word2vec and fastText approaches return fixed vectors---a word has the same vector regardless of the context in which it is inserted.
This is a known limitation of these models because they attribute the same vector to a word that may have different meanings depending on which context appears.
Lately, to counteract this issue, more advanced word representations have been proposed.
These are known as \textit{contextualized word representations} where the calculation of word vectors is made on-the-fly to take into account the context in which the words are inserted.

\as{elmo} (Embeddings from Language Models) proposed by \textcite{peters2018a} and
\as{bert} (Bidirectional Encoder Representations from Transformers) proposed by \textcite{devlin2019a} are arguably the two most used contextualized representations and have improved results considerably for a variety of \as{nlp} tasks.
Since the publication of \as{bert}, many variants have been pre-trained on biomedical and clinical textual data including BioBERT \parencite{lee2020a}, PubMedBERT \parencite{gu2021a}, and ClinicalBERT \parencite{alsentzer2019a,huang2019c}.
The exploration of these models is in our opinion a viable research direction.
For instance, \textcite{peng2019a} made an extensive evaluation of BERT and ELMo on ten datasets for biomedical \as{nlp} presenting several improvements over the state-of-the-art.

Another interesting idea is to explore token-free models that do not require the tokenization step and operate directly at the byte- or character-level.
A recent example of such models is the ByT5 architecture \parencite{xue2021b} where the authors use a standard transformer architecture to process byte sequences.
These models have the advantage of easily process text in any language and remove errors from the text pre-processing pipeline.

Our studies in biomedical information extraction were restricted to the English language because research is commonly most updated for the English idiom and there is a lag in developing resources such as annotated corpora, curated databases, and word embeddings models in other languages.
We consider that the resolution of biomedical \as{nlp} tasks in other languages is an under-researched area.
To the best of our knowledge, \textcite{ferreira2011a} presents the first information extraction system to process clinical records written in European Portuguese.
\textcite{schneider2020a} transfer-learned information from a multilingual \as{bert} to a corpora of clinical and biomedical text in Brazilian Portuguese releasing the BioBERTpt model.
\textcite{silvaeoliveira2022a} present the first available Brazilian Portuguese corpus for clinical \as{nlp} tasks (SemClinBr).
And more recently, \textcite{mirandaescalada2022a} organized a shared task to promote the development of automatic methods for the recognition and normalization of disease mentions in Spanish clinical narratives.
Therefore we consider that targeting biomedical \as{nlp} tasks in other languages is a relevant future research direction.

Another emerging research area is the study of information extraction from text found on social media platforms such as Twitter and Reddit.
Although social media content might be about any topic, some of the users' posts may contain relevant clinical information such as adverse drug effects.
Users may share and discuss their current health status after taking a medicine or have undergone a medical procedure.
However, the processing of social media text poses particular challenges because text may be clumsy and contain misspellings, abbreviations, slang terms, and emojis.
One example of recent research on mining social media text is the detection of medication mentions from tweets \parencite{weissenbacher2019a,weissenbacher2021b,zhang2022e}.
Hence we argue that analysis of social media textual data is also relevant for biomedical discoveries and has potential for future research.

Finally, we believe that a robust idea that could improve our information extraction systems would be the use of neural network--based joint learning approaches, where multiple \as{nlp} tasks are trained and learned simultaneously, which minimizes error propagation from initial steps.
For example, the tasks of named entity recognition and relation extraction could be addressed together through joint learning as shown in previous research \parencite{bekoulis2018a,luo2020a}.

This thesis presented several ideas and methods for a wide range of \as{nlp} problems involving information extraction in the biomedical domain.
We believe that there is still much room for improvement and that biomedical text mining will continue to benefit greatly from deep learning breakthroughs and more curated resources.
